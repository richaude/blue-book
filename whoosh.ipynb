{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical guidance for Whoosh\n",
    "### By Ruowei Wang, in 2/1/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoosh is a fast, featureful full-text indexing and searching library implemented in pure Python with detailed documentation. Programmers can use it to easily add search functionality to their applications and websites. Every part of how Whoosh works can be extended or replaced to meet your needs exactly.\n",
    "\n",
    "Some of Whoosh's features include:\n",
    "\n",
    "1.Pythonic API. \n",
    "2.Pure-Python and Open source. No compilation or binary packages needed, no mysterious crashes.\n",
    "3.Fielded indexing and search.\n",
    "4.Fast indexing and retrieval -- faster than any other pure-Python search solution I know of. See Benchmarks (https://bitbucket.org/mchaput/whoosh/wiki/Benchmarks).\n",
    "5.Pluggable scoring algorithm (including BM25F), text analysis, storage, posting format, etc.\n",
    "6.Powerful query language (supporting inexact search and proximity search). \n",
    "7. Production-quality pure Python spell-checker (as far as I know, the only one). \n",
    "   See http://whoosh.readthedocs.io/en/latest/spelling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install whoosh:\n",
    "1. if you want to use it in jupyter notebook, you could use the command ``conda install whoosh``\n",
    "2. ``easy_install Whoosh`` and ``pip install Whoosh`` also works, If you have ``setuptools`` or ``pip`` installed.\n",
    "3. Download source releases from PyPI at http://pypi.python.org/pypi/Whoosh/. Using ``hg clone http://bitbucket.org/mchaput/whoosh``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start implementing Whoosh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.qparser import *\n",
    "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED,NUMERIC\n",
    "from whoosh.analysis import StemmingAnalyzer,StandardAnalyzer\n",
    "from whoosh import index\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document can have multiple fields, such as title, content, url, date, etc. Firstly, we need to create a schema for our corpus to specify these fields of documents in an index. \n",
    "\n",
    "The schema is the set of all possible fields in a document. Each individual document might only use a subset of the available fields in the schema.\n",
    "\n",
    "note:\n",
    "without a schema, the query parser in Whoosh will not process the text in the user query (i.e., cannot do phrase searching).\n",
    "\n",
    "Here is an example of creating a schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(year=NUMERIC(stored=True),\n",
    "                author=TEXT(analyzer=StandardAnalyzer(stoplist=None),stored=True),\n",
    "                title=TEXT(analyzer=StandardAnalyzer(stoplist=None),stored=True),\n",
    "                abstract=TEXT(analyzer=StandardAnalyzer(stoplist=None),stored=True),\n",
    "                body=TEXT(analyzer=StandardAnalyzer(stoplist=None)),\n",
    "                subject=KEYWORD(commas=True,scorable=True),\n",
    "                keywords=KEYWORD(commas=True, scorable=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the predefined field types I used:\n",
    "\n",
    "1.whoosh.fields.NUMERIC:\n",
    "This field stores int, long, or floating point numbers in a compact, sortable format.\n",
    "\n",
    "2.whoosh.fields.TEXT:\n",
    "TEXT fields can indexes the text and stores term positions (by default, ``TEXT(phrase=True)``) to allow phrase searching.\n",
    "This field uses ``StandardAnalyzer`` by default. To specify a different analyzer, use the analyzer keyword argument to the constructor, e.g. ``TEXT(analyzer=analysis.StemmingAnalyzer())``. \n",
    "The documentation of different analyzer is here: http://whoosh.readthedocs.io/en/latest/api/analysis.html#analyzers. ``StandardAnalyzer`` only lowercase the words and filter them with a simple stopword list. \n",
    "By default, TEXT fields are not stored, which means the content of this field will not be shown in the search result. Usually you will not want to store the body text in the search index, however, you can use TEXT(stored=True) to specify that the text should be stored in the index.\n",
    "\n",
    "3.whoosh.fields.KEYWORD:\n",
    "This field type is designed for space- or comma-separated keywords. This type is indexed and searchable (and optionally stored). It does not support phrase searching.\n",
    "To store the value of the field in the index, use ``stored=True`` in the constructor. To automatically lowercase the keywords before indexing them, use ``lowercase=True``. To separate the keywords by commas (to allow keywords containing spaces), use ``commas=True``, Otherwise the keywords are space-seperated. To use the keyword field for searching, use ``scorable=True``.\n",
    "\n",
    "Note: there are many other predefined fields for users to choose, see http://whoosh.readthedocs.io/en/latest/api/fields.html#pre-made-field-types.\n",
    "\n",
    "Note: Whoosh can also create a schema declaratively using the SchemaClass base class and pass the declarative class to create_in() or create_index() instead of a Schema instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our schema, we will index each document in the corpus. In this example, I just use two books \"Gone with the wind\" and \"Grimms' Fairy Tales\" for display. \n",
    "Note:\n",
    "1. Indexed fields must be passed a unicode value.\n",
    "2. opening a writer locks the index for writing. In a multi-threaded or multi-process environment, opening a writer may raise an error if a writer is already open. Advanced writer object \"whoosh.writing.AsyncWriter\" and \"whoosh.writing.BufferedWriter\" can solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to create an index in a dictionary\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "ix = index.create_in(\"indexdir\", schema)\n",
    "#open an existing index object\n",
    "ix = index.open_dir(\"indexdir\")\n",
    "#create a writer object to add documents to the index\n",
    "writer = ix.writer()\n",
    "#now we can add documents to the index\n",
    "\n",
    "abstract1=u'''It depicts the struggles of young Scarlett O'Hara, the spoiled daughter of a well-to-do plantation owner, who must use every means at her disposal to claw her way out of poverty following Sherman's destructive 'March to the Sea'. This historical novel features a Bildungsroman or coming-of-age story, with the title taken from a poem written by Ernest Dowson'''\n",
    "\n",
    "abstract2=u'''Children's and Household Tales (German: Kinder- und Hausmärchen) is a collection of fairy tales first published in 20 December 1812 by the Grimm brothers, Jacob and Wilhelm. The collection is commonly known in English as Grimms' Fairy Tales.'''\n",
    "\n",
    "writer.add_document(year=u\"1936\",\n",
    "                author=u\"Margaret Mitchell\",\n",
    "                title=u\"Gone with the wind\",\n",
    "                abstract=abstract1,\n",
    "                subject=u\"novel, love\",\n",
    "                keywords=u\"Scarlett, Rhett\")\n",
    "writer.add_document(year=u\"1812\",\n",
    "                author=u\" Jacob and Wilhelm\",\n",
    "                title=u\"Grimms' Fairy Tales\",\n",
    "                abstract=abstract2,\n",
    "                subject=u\"story, children\",\n",
    "                keywords=u\"The Frog King,  Rapunzel\")\n",
    "#close the writer and save the added documents in the index\n",
    "#you should call the commit() function once you finish adding the documents otherwise you will cause an error-\n",
    "#when you try to edit the index next time and open another writer. \n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After indexing the documents, we can write down the query and convert the query string into query object by the query parser.\n",
    "\n",
    "Create a whoosh.qparser.QueryParser object, pass it the name of the default field to search and the schema of the index you’ll be searching. \n",
    "\n",
    "Query parser is built on modular plug-ins. For example, ``qparser.WildcardPlugin``, which is already in the default plug-in list of parser, gives the parser the ability to search for wildcards. Some frequently used plug-ins are shown in the following code.  \n",
    "\n",
    "You can use the plugins argument when creating the object to override the default list of plug-ins, use ``add_plugin()`` and/or ``remove_plugin_class()`` to change the plug-ins included in the parser. \n",
    "\n",
    "Here is the list of available plug-ins:http://whoosh.readthedocs.io/en/latest/api/qparser.html#plug-ins.\n",
    "\n",
    "Note:\n",
    "very important!!! The query string should be a unicode value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(abstract:apple AND abstract:company AND abstract:department)\n"
     ]
    }
   ],
   "source": [
    "#parsing the query\n",
    "# this is just a simple parser with default field\n",
    "parser=QueryParser(\"abstract\",schema=schema) \n",
    "#if you want “unfielded” terms to search both the title and content fields,  use a whoosh.qparser.MultifieldParser\n",
    "#parser = MultifieldParser([\"title\", \"abstract\"], schema=schema)\n",
    "#call parse() on query to parse a query string into a query object\n",
    "result=parser.parse(u\"apple company department\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(abstract:apple AND abstract:company AND abstract:department)\n"
     ]
    }
   ],
   "source": [
    "#by default, the parser treats the words as if they were connected by AND. \n",
    "#Changing the \"group\" keyword argument if you want it connencted by Or.\n",
    "# parser = MultifieldParser([\"title\", \"abstract\"], schema=schema,group=OrGroup)\n",
    "result=parser.parse(u\"apple company department\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year:[ TO 2000}\n"
     ]
    }
   ],
   "source": [
    "# you can use .add_plugin() to make the parser more powerful\n",
    "#GtLtPlugin() lets you use >, <, >=, <=, =>, or =< after a field specifier, \n",
    "#and translates the expression into the equivalent range:\n",
    "parser.add_plugin(GtLtPlugin()) \n",
    "result=parser.parse(u\"year:<2000\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author:margare~\n",
      "<Hit {'abstract': \"It depicts the struggles of young Scarlett O'Hara, the spoiled daughter of a well-to-do plantation owner, who must use every means at her disposal to claw her way out of poverty following Sherman's destructive 'March to the Sea'. This historical novel features a Bildungsroman or coming-of-age story, with the title taken from a poem written by Ernest Dowson\", 'author': 'Margaret Mitchell', 'title': 'Gone with the wind', 'year': '1936'}>\n"
     ]
    }
   ],
   "source": [
    "#FuzzyTermPlugin lets you search for “fuzzy” terms, that is, terms that don’t have to match exactly. \n",
    "#The fuzzy term will match any similar term within a certain number of “edits” \n",
    "parser.add_plugin(FuzzyTermPlugin())\n",
    "result=parser.parse(u\"author:margare~\")#would match a document has Margare and all terms in the index within one “edit” of cat, for example Margaret insert t\n",
    "print(result)\n",
    "#searcher object is used for searching the matched documents\n",
    "#you can open the searcher using a with statement so the searcher is automatically closed when you’re done with it\n",
    "#ix is the document index we created before\n",
    "with ix.searcher() as searcher:\n",
    "    results=searcher.search(result)#The Results object acts like a list of the matched documents.\n",
    "    print (results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:\"gone the\"\n",
      "<Top 1 Results for Phrase('title', ['gone', 'the'], slop=2, boost=1.000000) runtime=0.0013510680000763386>\n"
     ]
    }
   ],
   "source": [
    "#The default phrase query tokenizes the text between the quotes and creates a search for those terms in proximity.\n",
    "# print parser.default_set()\n",
    "#use single quotation marks for the unicode string since double quotation marks are used to represent phrases here\n",
    "result=parser.parse(u'title:\"gonE the\"~2')# would match a document has wind within 2 words after gone\n",
    "print(result)\n",
    "with ix.searcher() as searcher:\n",
    "    results=searcher.search(result)\n",
    "    print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:go*\n",
      "<Top 1 Results for Prefix('title', 'go') runtime=0.0006878879994474119>\n",
      "<Hit {'abstract': \"It depicts the struggles of young Scarlett O'Hara, the spoiled daughter of a well-to-do plantation owner, who must use every means at her disposal to claw her way out of poverty following Sherman's destructive 'March to the Sea'. This historical novel features a Bildungsroman or coming-of-age story, with the title taken from a poem written by Ernest Dowson\", 'author': 'Margaret Mitchell', 'title': 'Gone with the wind', 'year': '1936'}>\n"
     ]
    }
   ],
   "source": [
    "#you can use * or ? for inexact term search\n",
    "#use ? to represent a single character and * to represent any number of characters\n",
    "result=parser.parse(u'title:go*')# would match a document has wind within 2 words after gone\n",
    "print(result)\n",
    "with ix.searcher() as searcher:\n",
    "    results=searcher.search(result)\n",
    "    print (results)\n",
    "    print (results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((abstract:child OR abstract:childr*) NEAR abstract:ho*sehold) AND title:tale*)\n",
      "\n",
      "\n",
      "<Top 1 Results for And([Sequence([Or([Term('abstract', 'child'), Prefix('abstract', 'childr')]), Wildcard('abstract', 'ho*sehold')], slop=3, boost=1.000000), Prefix('title', 'tale')]) runtime=0.001840543000071193>\n",
      "the position of the word pattern <tale*> in document <Grimms' Fairy Tales> is:\n",
      "[4, 14, 38]\n"
     ]
    }
   ],
   "source": [
    "#If you want to do more complex proximity searches, you can replace the phrase plugin with the whoosh.qparser.SequencePlugin.\n",
    "#It allows any query between the quotes.\n",
    "\n",
    "#remove the ability to specify phrase queries inside double quotes.\n",
    "parser.remove_plugin_class(PhrasePlugin)\n",
    "#Adds the ability to group arbitrary queries inside double quotes,\n",
    "#to produce a query matching the individual sub-queries in sequence.\n",
    "parser.add_plugin(SequencePlugin())\n",
    "#IMPORTANT!!! Not like phrase query which specify the field outside the double quotation marks,\n",
    "#you need to specify the field inside the double quotation marks for each subquery\n",
    "#the query string below represents the query 'abstract:\"(child OR childr*) ho*sehold\"~3 AND title:tales' \n",
    "result=parser.parse(u'\"abstract:(child OR childr*) abstract:ho*sehold\"~3 AND title:tale*')\n",
    "print (result)\n",
    "print(\"\\n\")\n",
    "with ix.searcher() as searcher:\n",
    "    results=searcher.search(result)\n",
    "    print (results)\n",
    "#     print (results[0])\n",
    "    #we can get the position of a term by doing it manually\n",
    "    import re\n",
    "    for result in results:\n",
    "        analyzer=StandardAnalyzer(stoplist=None)\n",
    "        a=[(t.pos) for t in analyzer(result['abstract'],positions=True) if re.match(r\"tale*\",t.text)]\n",
    "        print(\"the position of the word pattern \"+\"<tale*> \"+\"in document <\"+result['title']+\"> is:\")\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference:\n",
    "Whoosh documentation website. http://whoosh.readthedocs.io/en/latest/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
